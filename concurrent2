import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed

# Function to fetch the content of a URL
def fetch_url(url):
    try:
        response = requests.get(url, timeout=10)  # Set a timeout to avoid hanging requests
        return response.text
    except Exception as e:
        return f"Error: {e}"

# Main function
def main():
    # Read the CSV file delimited by "|"
    df = pd.read_csv("test.csv", delimiter="|")

    # Ensure the "urls" column exists
    if "urls" not in df.columns:
        raise ValueError("Column 'urls' not found in the CSV file.")

    # Drop NaN values from the URLs column
    urls = df["urls"].dropna().tolist()

    # List to store responses
    responses = []

    # Use ThreadPoolExecutor for concurrency
    with ThreadPoolExecutor(max_workers=5) as executor:
        # Submit tasks to the executor
        future_to_url = {executor.submit(fetch_url, url): url for url in urls}

        # Collect responses as they complete
        for future in as_completed(future_to_url):
            try:
                responses.append(future.result())
            except Exception as e:
                responses.append(f"Error: {e}")

    # Add the responses as a new column
    df["response_body"] = pd.Series(responses)

    # Write the resulting DataFrame to a Parquet file
    df.to_parquet("output.parquet", engine="pyarrow", index=False)

# Execute the main function
if __name__ == "__main__":
    main()
