import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor
import pyarrow.parquet as pq

# Read the CSV file with | delimited
df = pd.read_csv('input.csv', delimiter='|')

# Create a new column to store the response
df['response'] = ''

# Define a function to make a GET request and return the response
def make_request(url):
    try:
        response = requests.get(url)
        return response.text
    except requests.exceptions.RequestException as e:
        return str(e)

# Use ThreadPoolExecutor to make concurrent requests
with ThreadPoolExecutor(max_workers=2) as executor:
    futures = []
    for index, row in df.iterrows():
        url = row['urls']
        futures.append(executor.submit(make_request, url))

    # Get the results and update the DataFrame
    for index, future in enumerate(futures):
        (link unavailable)[index, 'response'] = future.result()

# Write the updated DataFrame to a Parquet file using append
table = pq.Table.from_pandas(df)
pq.write_to_dataset(table, 'output.parquet', compression='snappy', use_dictionary=True, chunksize=10000)

