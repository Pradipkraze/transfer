import pandas as pd
import requests

def process_csv(input_file, output_file, url_column, response_column='Response'):
    """
    Reads a pipe-delimited CSV, fetches GET responses for URLs in the specified column,
    and writes the updated DataFrame to a new pipe-delimited CSV.
    
    Parameters:
        input_file (str): Path to the input CSV file.
        output_file (str): Path to save the output CSV file.
        url_column (str): The column name containing the URLs.
        response_column (str): The column name for storing response bodies (default 'Response').
    """
    # Read the pipe-delimited CSV
    df = pd.read_csv(input_file, delimiter='|')

    # Validate URL column
    if url_column not in df.columns:
        raise ValueError(f"The specified URL column '{url_column}' is not in the CSV.")

    # Fetch GET responses and store in a new column
    responses = []
    for url in df[url_column]:
        try:
            # Fetch the URL
            response = requests.get(url)
            response.raise_for_status()  # Raise an error for bad status codes
            responses.append(response.text)
        except requests.exceptions.RequestException as e:
            responses.append(f"Error: {e}")

    # Add the responses to the DataFrame
    df[response_column] = responses

    # Save the updated DataFrame to a new pipe-delimited CSV
    df.to_csv(output_file, sep='|', index=False)
    print(f"Updated CSV saved to {output_file}")


# Example usage
input_csv = "test.csv"  # Replace with the actual input file path
output_csv = "test_with_responses.csv"  # Replace with the desired output file path
url_column_name = "URLs"  # Replace with the actual column name containing URLs

process_csv(input_csv, output_csv, url_column_name)
